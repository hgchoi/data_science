{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tracking User Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, I've created a service at an ed tech firm that\n",
    "delivers assessments, and now lots of different customers (e.g., Pearson) want\n",
    "to publish their assessments on it. I need to prepare for data scientists\n",
    "who work for these customers to run queries on the data. \n",
    "\n",
    "### Tasks\n",
    "\n",
    "Prepare the infrastructure to land the data in the form and structure it needs\n",
    "to be to be queried. I need to:\n",
    "\n",
    "- Publish and consume messages with Kafka\n",
    "- Use Spark to transform the messages. \n",
    "- Use Spark to transform the messages so that I can land them in HDFS\n",
    "\n",
    "I have included my `docker-compose.yml` used for spinning the pipeline. \n",
    "\n",
    "I've also included the history of my console by running\n",
    "```\n",
    "history > <user-name>-history.txt\n",
    "```\n",
    "\n",
    "I ran Spark by running a Jupyter Notebook against a pyspark kernel.\n",
    "\n",
    "In order to show the data scientists at these other companies the kinds of data\n",
    "that they will have access to, I decided on a few basic business questions that\n",
    "I believed they might need to answer about these data.\n",
    "\n",
    "### Data\n",
    "\n",
    "Note on the data: This dataset is a nested JSON file, where I need to unwrap it\n",
    "carefully to understand what's really being displayed. There are many fields\n",
    "that were not important for my analysis, so many were left untouched.\n",
    "The main problem was the multiple questions field. \n",
    "Documentation for reading schema implementation in Spark [Here is the documenation from\n",
    "Apache](https://spark.apache.org/docs/2.3.0/sql-programming-guide.html).\n",
    "\n",
    "\n",
    "### Business Questions Answered \n",
    "\n",
    "1. How many assesstments are in the dataset?\n",
    "2. How many people took *Learning Git*?\n",
    "3. How many people got As on their exams?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linux Commands\n",
    "\n",
    "### Bring up cluster and ensure that it is running\n",
    "``` \n",
    "docker-compose up -d\n",
    "docker-compose ps \n",
    "docker ps -a\n",
    "```\n",
    "\n",
    "### Create the topic\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --create --topic assessments --partitions 1 --replication-factor 1 --if-not-exists --zookeeper zookeeper:32181\n",
    "```\n",
    "\n",
    "### Check the topic\n",
    "\n",
    "```\n",
    "docker-compose exec kafka kafka-topics --describe --topic assessments --zookeeper zookeeper:32181 \n",
    "``` \n",
    "\n",
    "\n",
    "### Start the kafka logs \n",
    "\n",
    "```\n",
    "docker-compose logs -f kafka\n",
    "```\n",
    "\n",
    "### Put the json objects on the kafka topic\n",
    "``` \n",
    "docker-compose exec mids bash -c \"cat /w205/project-2-hgchoi/assessment-attempts-20180128-121051-nested.json | jq '.[]' -c | kafkacat -P -b kafka:29092 -t assessments\" \n",
    "```\n",
    "\n",
    "### Read the topic with kafkacat to make sure everything is on it\n",
    "\n",
    "```\n",
    "docker-compose exec mids bash -c \"kafkacat -C -b kafka:29092 -t assessments -o beginning -e\" \n",
    "```\n",
    "\n",
    "### Shutdown the cluster\n",
    "```\n",
    "docker-compose down\n",
    "docker-compose up -d\n",
    "docker-compose ps\n",
    "docker ps -a\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print json file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "p = pprint.PrettyPrinter(indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f = open(\"assessment-attempts-20180128-121051-nested.json\",\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "s = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "json_data = json.loads(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3280"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'base_exam_id': '37f0a30a-7464-11e6-aa92-a8667f27e5dc',\n",
      " 'certification': 'false',\n",
      " 'exam_name': 'Normal Forms and All That Jazz Master Class',\n",
      " 'keen_created_at': '1516717442.735266',\n",
      " 'keen_id': '5a6745820eb8ab00016be1f1',\n",
      " 'keen_timestamp': '1516717442.735266',\n",
      " 'max_attempts': '1.0',\n",
      " 'sequences': {'attempt': 1,\n",
      "               'counts': {'all_correct': False,\n",
      "                          'correct': 2,\n",
      "                          'incomplete': 1,\n",
      "                          'incorrect': 1,\n",
      "                          'submitted': 4,\n",
      "                          'total': 4,\n",
      "                          'unanswered': 0},\n",
      "               'id': '5b28a462-7a3b-42e0-b508-09f3906d1703',\n",
      "               'questions': [{'id': '7a2ed6d3-f492-49b3-b8aa-d080a8aad986',\n",
      "                              'options': [{'at': '2018-01-23T14:23:24.670Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': '49c574b4-5c82-4ffd-9bd1-c3358faf850d',\n",
      "                                           'submitted': 1},\n",
      "                                          {'at': '2018-01-23T14:23:25.914Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': 'f2528210-35c3-4320-acf3-9056567ea19f',\n",
      "                                           'submitted': 1},\n",
      "                                          {'checked': False,\n",
      "                                           'correct': True,\n",
      "                                           'id': 'd1bf026f-554f-4543-bdd2-54dcf105b826'}],\n",
      "                              'user_correct': False,\n",
      "                              'user_incomplete': True,\n",
      "                              'user_result': 'missed_some',\n",
      "                              'user_submitted': True},\n",
      "                             {'id': 'bbed4358-999d-4462-9596-bad5173a6ecb',\n",
      "                              'options': [{'at': '2018-01-23T14:23:30.116Z',\n",
      "                                           'checked': True,\n",
      "                                           'id': 'a35d0e80-8c49-415d-b8cb-c21a02627e2b',\n",
      "                                           'submitted': 1},\n",
      "                                          {'checked': False,\n",
      "                                           'correct': True,\n",
      "                                           'id': 'bccd6e2e-2cef-4c72-8bfa-317db0ac48bb'},\n",
      "                                          {'at': '2018-01-23T14:23:41.791Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': '7e0b639a-2ef8-4604-b7eb-5018bd81a91b',\n",
      "                                           'submitted': 1}],\n",
      "                              'user_correct': False,\n",
      "                              'user_incomplete': False,\n",
      "                              'user_result': 'incorrect',\n",
      "                              'user_submitted': True},\n",
      "                             {'id': 'e6ad8644-96b1-4617-b37b-a263dded202c',\n",
      "                              'options': [{'at': '2018-01-23T14:23:52.510Z',\n",
      "                                           'checked': False,\n",
      "                                           'id': 'a9333679-de9d-41ff-bb3d-b239d6b95732'},\n",
      "                                          {'checked': False,\n",
      "                                           'id': '85795acc-b4b1-4510-bd6e-41648a3553c9'},\n",
      "                                          {'at': '2018-01-23T14:23:54.223Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': 'c185ecdb-48fb-4edb-ae4e-0204ac7a0909',\n",
      "                                           'submitted': 1},\n",
      "                                          {'at': '2018-01-23T14:23:53.862Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': '77a66c83-d001-45cd-9a5a-6bba8eb7389e',\n",
      "                                           'submitted': 1}],\n",
      "                              'user_correct': True,\n",
      "                              'user_incomplete': False,\n",
      "                              'user_result': 'correct',\n",
      "                              'user_submitted': True},\n",
      "                             {'id': '95194331-ac43-454e-83de-ea8913067055',\n",
      "                              'options': [{'checked': False,\n",
      "                                           'id': '59b9fc4b-f239-4850-b1f9-912d1fd3ca13'},\n",
      "                                          {'checked': False,\n",
      "                                           'id': '2c29e8e8-d4a8-406e-9cdf-de28ec5890fe'},\n",
      "                                          {'checked': False,\n",
      "                                           'id': '62feee6e-9b76-4123-bd9e-c0b35126b1f1'},\n",
      "                                          {'at': '2018-01-23T14:24:00.807Z',\n",
      "                                           'checked': True,\n",
      "                                           'correct': True,\n",
      "                                           'id': '7f13df9c-fcbe-4424-914f-2206f106765c',\n",
      "                                           'submitted': 1}],\n",
      "                              'user_correct': True,\n",
      "                              'user_incomplete': False,\n",
      "                              'user_result': 'correct',\n",
      "                              'user_submitted': True}]},\n",
      " 'started_at': '2018-01-23T14:23:19.082Z',\n",
      " 'user_exam_id': '6d4089e4-bde5-4a22-b65f-18bce9ab79c8'}\n"
     ]
    }
   ],
   "source": [
    "# this will pretty print the json in alphabetic order which may or may not match the file order\n",
    "p.pprint(json_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def recursive_walk_json_object(j, level):\n",
    "    \"\"\"recursively walk through a json object to explore the structure\n",
    "       dictionaries will be put in alphabetic order to match the pretty print above\"\"\"\n",
    "    \n",
    "    level += 1\n",
    "    \n",
    "    if type(j) is dict:\n",
    "        dict_2_list = list(j.keys())\n",
    "        dict_2_list.sort()\n",
    "        for k in dict_2_list:\n",
    "            print(\"   \" * level + \"L\" + str(level), k)\n",
    "            recursive_walk_json_object(j[k], level)\n",
    "    \n",
    "    elif type(j) is list:\n",
    "        for (i, l) in enumerate(j):\n",
    "            print(\"  \" * level + \"  [\" + str(i) + \"]\")\n",
    "            recursive_walk_json_object(l, level)\n",
    "            \n",
    "    else:\n",
    "        print(\"   \" * level + \" value:\", j)\n",
    "                    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L0 base_exam_id\n",
      "    value: 37f0a30a-7464-11e6-aa92-a8667f27e5dc\n",
      "L0 certification\n",
      "    value: false\n",
      "L0 exam_name\n",
      "    value: Normal Forms and All That Jazz Master Class\n",
      "L0 keen_created_at\n",
      "    value: 1516717442.735266\n",
      "L0 keen_id\n",
      "    value: 5a6745820eb8ab00016be1f1\n",
      "L0 keen_timestamp\n",
      "    value: 1516717442.735266\n",
      "L0 max_attempts\n",
      "    value: 1.0\n",
      "L0 sequences\n",
      "   L1 attempt\n",
      "       value: 1\n",
      "   L1 counts\n",
      "      L2 all_correct\n",
      "          value: False\n",
      "      L2 correct\n",
      "          value: 2\n",
      "      L2 incomplete\n",
      "          value: 1\n",
      "      L2 incorrect\n",
      "          value: 1\n",
      "      L2 submitted\n",
      "          value: 4\n",
      "      L2 total\n",
      "          value: 4\n",
      "      L2 unanswered\n",
      "          value: 0\n",
      "   L1 id\n",
      "       value: 5b28a462-7a3b-42e0-b508-09f3906d1703\n",
      "   L1 questions\n",
      "      [0]\n",
      "         L3 id\n",
      "             value: 7a2ed6d3-f492-49b3-b8aa-d080a8aad986\n",
      "         L3 options\n",
      "          [0]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:24.670Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: 49c574b4-5c82-4ffd-9bd1-c3358faf850d\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "          [1]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:25.914Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: f2528210-35c3-4320-acf3-9056567ea19f\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "          [2]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: d1bf026f-554f-4543-bdd2-54dcf105b826\n",
      "         L3 user_correct\n",
      "             value: False\n",
      "         L3 user_incomplete\n",
      "             value: True\n",
      "         L3 user_result\n",
      "             value: missed_some\n",
      "         L3 user_submitted\n",
      "             value: True\n",
      "      [1]\n",
      "         L3 id\n",
      "             value: bbed4358-999d-4462-9596-bad5173a6ecb\n",
      "         L3 options\n",
      "          [0]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:30.116Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: a35d0e80-8c49-415d-b8cb-c21a02627e2b\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "          [1]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: bccd6e2e-2cef-4c72-8bfa-317db0ac48bb\n",
      "          [2]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:41.791Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: 7e0b639a-2ef8-4604-b7eb-5018bd81a91b\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "         L3 user_correct\n",
      "             value: False\n",
      "         L3 user_incomplete\n",
      "             value: False\n",
      "         L3 user_result\n",
      "             value: incorrect\n",
      "         L3 user_submitted\n",
      "             value: True\n",
      "      [2]\n",
      "         L3 id\n",
      "             value: e6ad8644-96b1-4617-b37b-a263dded202c\n",
      "         L3 options\n",
      "          [0]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:52.510Z\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 id\n",
      "                   value: a9333679-de9d-41ff-bb3d-b239d6b95732\n",
      "          [1]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 id\n",
      "                   value: 85795acc-b4b1-4510-bd6e-41648a3553c9\n",
      "          [2]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:54.223Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: c185ecdb-48fb-4edb-ae4e-0204ac7a0909\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "          [3]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:23:53.862Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: 77a66c83-d001-45cd-9a5a-6bba8eb7389e\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "         L3 user_correct\n",
      "             value: True\n",
      "         L3 user_incomplete\n",
      "             value: False\n",
      "         L3 user_result\n",
      "             value: correct\n",
      "         L3 user_submitted\n",
      "             value: True\n",
      "      [3]\n",
      "         L3 id\n",
      "             value: 95194331-ac43-454e-83de-ea8913067055\n",
      "         L3 options\n",
      "          [0]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 id\n",
      "                   value: 59b9fc4b-f239-4850-b1f9-912d1fd3ca13\n",
      "          [1]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 id\n",
      "                   value: 2c29e8e8-d4a8-406e-9cdf-de28ec5890fe\n",
      "          [2]\n",
      "               L5 checked\n",
      "                   value: False\n",
      "               L5 id\n",
      "                   value: 62feee6e-9b76-4123-bd9e-c0b35126b1f1\n",
      "          [3]\n",
      "               L5 at\n",
      "                   value: 2018-01-23T14:24:00.807Z\n",
      "               L5 checked\n",
      "                   value: True\n",
      "               L5 correct\n",
      "                   value: True\n",
      "               L5 id\n",
      "                   value: 7f13df9c-fcbe-4424-914f-2206f106765c\n",
      "               L5 submitted\n",
      "                   value: 1\n",
      "         L3 user_correct\n",
      "             value: True\n",
      "         L3 user_incomplete\n",
      "             value: False\n",
      "         L3 user_result\n",
      "             value: correct\n",
      "         L3 user_submitted\n",
      "             value: True\n",
      "L0 started_at\n",
      "    value: 2018-01-23T14:23:19.082Z\n",
      "L0 user_exam_id\n",
      "    value: 6d4089e4-bde5-4a22-b65f-18bce9ab79c8\n"
     ]
    }
   ],
   "source": [
    "recursive_walk_json_object(json_data[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unroll Assessments Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_assessments = spark.read.format(\"kafka\").option(\"kafka.bootstrap.servers\", \"kafka:29092\").option(\"subscribe\",\"assessments\").option(\"startingOffsets\", \"earliest\").option(\"endingOffsets\", \"latest\").load() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: binary, value: binary, topic: string, partition: int, offset: bigint, timestamp: timestamp, timestampType: int]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_assessments.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "assessments = raw_assessments.select(raw_assessments.value.cast('string'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "extracted_assessments = assessments.rdd.map(lambda x: Row(**json.loads(x.value))).toDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame[value: string]\n"
     ]
    }
   ],
   "source": [
    "extracted_assessments.registerTempTable('assessments')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|             keen_id|\n",
      "+--------------------+\n",
      "|5a6745820eb8ab000...|\n",
      "|5a674541ab6b0a000...|\n",
      "|5a67999d3ed3e3000...|\n",
      "|5a6799694fc7c7000...|\n",
      "|5a6791e824fccd000...|\n",
      "|5a67a0b6852c2a000...|\n",
      "|5a67b627cc80e6000...|\n",
      "|5a67ac8cb0a5f4000...|\n",
      "|5a67a9ba060087000...|\n",
      "|5a67ac54411aed000...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select keen_id from assessments limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-------------------------------------------------------+\n",
      "|    keen_timestamp|sequences[questions] AS `questions`[0][user_incomplete]|\n",
      "+------------------+-------------------------------------------------------+\n",
      "| 1516717442.735266|                                                   true|\n",
      "| 1516717377.639827|                                                  false|\n",
      "| 1516738973.653394|                                                  false|\n",
      "|1516738921.1137421|                                                  false|\n",
      "| 1516737000.212122|                                                  false|\n",
      "| 1516740790.309757|                                                  false|\n",
      "|1516746279.3801291|                                                  false|\n",
      "| 1516743820.305464|                                                  false|\n",
      "|  1516743098.56811|                                                  false|\n",
      "| 1516743764.813107|                                                  false|\n",
      "+------------------+-------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select keen_timestamp, sequences.questions[0].user_incomplete from assessments limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract sequence.id by writing a custom lambda transform, creating a separate data frame, registering it as a temp table, and use spark SQL to join it to the outer nesting layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def my_lambda_sequences_id(x):\n",
    "    raw_dict = json.loads(x.value)\n",
    "    my_dict = {\"keen_id\" : raw_dict[\"keen_id\"], \"sequences_id\" : raw_dict[\"sequences\"][\"id\"]}\n",
    "    return Row(**my_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_sequences = assessments.rdd.map(my_lambda_sequences_id).toDF()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_sequences.registerTempTable('sequences')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|        sequences_id|\n",
      "+--------------------+\n",
      "|5b28a462-7a3b-42e...|\n",
      "|5b28a462-7a3b-42e...|\n",
      "|b370a3aa-bf9e-4c1...|\n",
      "|b370a3aa-bf9e-4c1...|\n",
      "|04a192c1-4f5c-4ac...|\n",
      "|e7110aed-0d08-4cb...|\n",
      "|5251db24-2a6e-424...|\n",
      "|066b5326-e547-4da...|\n",
      "|8ac691f8-8c1a-403...|\n",
      "|066b5326-e547-4da...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select sequences_id from sequences limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+\n",
      "|             keen_id|    keen_timestamp|        sequences_id|\n",
      "+--------------------+------------------+--------------------+\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|8ac691f8-8c1a-403...|\n",
      "|5a26ee9cbf5ce1000...|1512500892.4166169|9bd87823-4508-4e0...|\n",
      "+--------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select a.keen_id, a.keen_timestamp, s.sequences_id from assessments a join sequences s on a.keen_id = s.keen_id limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nested multi-valued as a list: pull out all values from the list by writing a custom labmda transform, creating a another data frame, registering it as a temp table, and joining it to data frames of outer nesting layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                  id|my_count|\n",
      "+--------------------+--------+\n",
      "|7a2ed6d3-f492-49b...|       1|\n",
      "|bbed4358-999d-446...|       2|\n",
      "|e6ad8644-96b1-461...|       3|\n",
      "|95194331-ac43-454...|       4|\n",
      "|95194331-ac43-454...|       1|\n",
      "|bbed4358-999d-446...|       2|\n",
      "|e6ad8644-96b1-461...|       3|\n",
      "|7a2ed6d3-f492-49b...|       4|\n",
      "|b9ff2e88-cf9d-4bd...|       1|\n",
      "|bec23e7b-4870-49f...|       2|\n",
      "+--------------------+--------+\n",
      "\n",
      "+--------------------+------------------+--------------------+\n",
      "|             keen_id|    keen_timestamp|                  id|\n",
      "+--------------------+------------------+--------------------+\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|32fe7d8d-6d89-4db...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|5c34cf19-8cfd-4f5...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|32fe7d8d-6d89-4db...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|5c34cf19-8cfd-4f5...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "+--------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def my_lambda_questions(x):\n",
    "    raw_dict = json.loads(x.value)\n",
    "    my_list = []\n",
    "    my_count = 0\n",
    "    for l in raw_dict[\"sequences\"][\"questions\"]:\n",
    "        my_count += 1\n",
    "        my_dict = {\"keen_id\" : raw_dict[\"keen_id\"], \"my_count\" : my_count, \"id\" : l[\"id\"]}\n",
    "        my_list.append(Row(**my_dict))\n",
    "    return my_list\n",
    "\n",
    "my_questions = assessments.rdd.flatMap(my_lambda_questions).toDF()\n",
    "\n",
    "my_questions.registerTempTable('questions')\n",
    "\n",
    "spark.sql(\"select id, my_count from questions limit 10\").show()\n",
    "\n",
    "spark.sql(\"select q.keen_id, a.keen_timestamp, q.id from assessments a join questions q on a.keen_id = q.keen_id limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_questions = assessments.rdd.flatMap(my_lambda_questions).toDF()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_questions.registerTempTable('questions')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|                  id|my_count|\n",
      "+--------------------+--------+\n",
      "|7a2ed6d3-f492-49b...|       1|\n",
      "|bbed4358-999d-446...|       2|\n",
      "|e6ad8644-96b1-461...|       3|\n",
      "|95194331-ac43-454...|       4|\n",
      "|95194331-ac43-454...|       1|\n",
      "|bbed4358-999d-446...|       2|\n",
      "|e6ad8644-96b1-461...|       3|\n",
      "|7a2ed6d3-f492-49b...|       4|\n",
      "|b9ff2e88-cf9d-4bd...|       1|\n",
      "|bec23e7b-4870-49f...|       2|\n",
      "+--------------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select id, my_count from questions limit 10\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+--------------------+\n",
      "|             keen_id|    keen_timestamp|                  id|\n",
      "+--------------------+------------------+--------------------+\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|32fe7d8d-6d89-4db...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|5c34cf19-8cfd-4f5...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|32fe7d8d-6d89-4db...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|5c34cf19-8cfd-4f5...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|803fc93f-7eb2-412...|\n",
      "|5a17a67efa1257000...|1511499390.3836269|f3cb88cc-5b79-41b...|\n",
      "+--------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select q.keen_id, a.keen_timestamp, q.id from assessments a join questions q on a.keen_id = q.keen_id limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling \"holes\" in json data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def my_lambda_correct_total(x):\n",
    "    \n",
    "    raw_dict = json.loads(x.value)\n",
    "    my_list = []\n",
    "    \n",
    "    if \"sequences\" in raw_dict:\n",
    "        \n",
    "        if \"counts\" in raw_dict[\"sequences\"]:\n",
    "            \n",
    "            if \"correct\" in raw_dict[\"sequences\"][\"counts\"] and \"total\" in raw_dict[\"sequences\"][\"counts\"]:\n",
    "                    \n",
    "                my_dict = {\"correct\": raw_dict[\"sequences\"][\"counts\"][\"correct\"], \n",
    "                           \"total\": raw_dict[\"sequences\"][\"counts\"][\"total\"]}\n",
    "                my_list.append(Row(**my_dict))\n",
    "    \n",
    "    return my_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_correct_total = assessments.rdd.flatMap(my_lambda_correct_total).toDF()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_correct_total.registerTempTable('ct')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|correct|total|\n",
      "+-------+-----+\n",
      "|      2|    4|\n",
      "|      1|    4|\n",
      "|      3|    4|\n",
      "|      2|    4|\n",
      "|      3|    4|\n",
      "|      5|    5|\n",
      "|      1|    1|\n",
      "|      5|    5|\n",
      "|      4|    4|\n",
      "|      0|    5|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from ct limit 10\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "|  0.5|\n",
      "| 0.25|\n",
      "| 0.75|\n",
      "|  0.5|\n",
      "| 0.75|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select correct / total as score from ct limit 10\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|        avg_score|\n",
      "+-----------------+\n",
      "|62.65699745547132|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select avg(correct / total)*100 as avg_score from ct limit 10\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|standard_deviation|\n",
      "+------------------+\n",
      "| 0.310835277631016|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select stddev(correct / total) as standard_deviation from ct limit 10\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write dataframes out to Hadoop HDFS in Parquet format to create a batch and serving layers scale up SQL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "raw_assessments.write.mode('overwrite').parquet(\"/tmp/raw_assessments\")\n",
    "\n",
    "assessments.write.mode('overwrite').parquet(\"/tmp/assessments\")\n",
    "\n",
    "extracted_assessments.write.mode('overwrite').parquet(\"/tmp/extracted_assessments\")\n",
    "\n",
    "my_sequences.write.mode('overwrite').parquet(\"/tmp/my_sequences\")\n",
    "\n",
    "my_questions.write.mode('overwrite').parquet(\"/tmp/my_questions\")\n",
    "\n",
    "my_correct_total.write.mode('overwrite').parquet(\"/tmp/my_correct_total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Questions and Answers Using Spark SQL against MPP Dataframe/RDD in Memory "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "##### 1) How many assessments are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+\n",
      "|number_of_assessments|\n",
      "+---------------------+\n",
      "|                 9840|\n",
      "+---------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as number_of_assessments from assessments\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2) How many people took the class Learning Git?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------------+\n",
      "|students_who_took_learning_git|\n",
      "+------------------------------+\n",
      "|                          1182|\n",
      "+------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as students_who_took_learning_git from assessments where exam_name = 'Learning Git'\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3) How many people got As on their exams?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|students_who_got_As|\n",
      "+-------------------+\n",
      "|                  4|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) as students_who_got_As from scores where score >= 0.9\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### Write a query, save that query to a new dataframe, register that dataframe as a temp table, then execute a query against the new temp table "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_scores = spark.sql(\"select correct / total as score from ct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|             score|\n",
      "+------------------+\n",
      "|               0.5|\n",
      "|              0.25|\n",
      "|              0.75|\n",
      "|               0.5|\n",
      "|              0.75|\n",
      "|               1.0|\n",
      "|               1.0|\n",
      "|               1.0|\n",
      "|               1.0|\n",
      "|               0.0|\n",
      "|              0.75|\n",
      "|               1.0|\n",
      "|0.6666666666666666|\n",
      "|0.6666666666666666|\n",
      "|               0.8|\n",
      "|              0.75|\n",
      "|              0.75|\n",
      "|               1.0|\n",
      "|               0.5|\n",
      "|               1.0|\n",
      "+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_scores.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "my_scores.registerTempTable(\"scores\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "|  0.5|\n",
      "| 0.25|\n",
      "| 0.75|\n",
      "|  0.5|\n",
      "| 0.75|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select correct / total as score from ct limit 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "|  0.5|\n",
      "| 0.25|\n",
      "| 0.75|\n",
      "|  0.5|\n",
      "| 0.75|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  0.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select * from scores\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+\n",
      "|score|\n",
      "+-----+\n",
      "| 0.75|\n",
      "| 0.75|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "|  1.0|\n",
      "+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_scores_gt_70_pct = spark.sql(\"select * from scores where score > 0.7 \").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m55",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m55"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
